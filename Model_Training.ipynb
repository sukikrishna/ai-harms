{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ccQqT8fK_s-",
    "outputId": "c712db94-2307-4d87-bf7a-d04ad9c77776"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Svcd3tSHLIWf"
   },
   "outputs": [],
   "source": [
    "# Go to this folder: https://drive.google.com/drive/folders/1MbxJkTyZX-S9jZYYC-BWK4yeFqVBW-Mf?usp=drive_link\n",
    "# Use the files final_features and final_outcomes\n",
    "\n",
    "df_features = pd.read_csv(\"features_final_v2.csv\")\n",
    "df_outcomes = pd.read_csv(\"final_outcomes.csv\")\n",
    "\n",
    "median_los = df_outcomes['length_of_stay'].median()\n",
    "df_outcomes['prolonged_length_of_stay'] = (df_outcomes['length_of_stay'] > median_los).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "U9ExvZaBPxjF",
    "outputId": "3e74c2ce-f7f6-40dc-900b-f4d9758601cd"
   },
   "outputs": [],
   "source": [
    "df_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "Dx1Vj8q6Cb2S",
    "outputId": "9bad166c-5a42-404a-8bb9-bc017cd25f88"
   },
   "outputs": [],
   "source": [
    "df_outcomes['aki_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5GjFwcPCn3x",
    "outputId": "b6c10b93-0d97-42a4-c696-903386fe34fb"
   },
   "outputs": [],
   "source": [
    "df_outcomes['length_of_stay'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "WikBGMGxBAYo",
    "outputId": "e642ccd3-01c3-4802-8dd2-b1cf44f7c7ab"
   },
   "outputs": [],
   "source": [
    "df_outcomes['aki_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_ewfb0Tn_ZZ"
   },
   "source": [
    "# Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpFiuC1Hn-Vs"
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'length_of_stay_use_apache': [\n",
    "        'age',\n",
    "        'has_heartdisease',\n",
    "        'has_diabetes',\n",
    "        'has_cancer',\n",
    "        'has_esrf',\n",
    "        'apache_temperature',\n",
    "        'apache_heartrate',\n",
    "        'apache_fio2',\n",
    "        'systolic_noninvasive',\n",
    "        'systolic_invasive',\n",
    "        'wbc1000',\n",
    "        'sodium',\n",
    "        'potassium',\n",
    "        'apache_gcs',\n",
    "        'bilirubin',\n",
    "        'bicarbonate'\n",
    "    ],\n",
    "    'length_of_stay': [\n",
    "        'age',\n",
    "        'has_heartdisease',\n",
    "        'has_diabetes',\n",
    "        'has_cancer',\n",
    "        'has_esrf',\n",
    "        'apache_temperature',\n",
    "        'temperature',\n",
    "        'apache_heartrate',\n",
    "        'heartrate',\n",
    "        'pao2_fio2_ratio',\n",
    "        'systolic_noninvasive',\n",
    "        'systolic_invasive',\n",
    "        'wbc1000',\n",
    "        'sodium',\n",
    "        'potassium',\n",
    "        'apache_gcs',\n",
    "        'bilirubin',\n",
    "        'bicarbonate'\n",
    "    ],\n",
    "    'mortality': [\n",
    "        # paper for the features: https://pmc.ncbi.nlm.nih.gov/articles/PMC7332047\n",
    "        # - We made some minor modifications with regards to these features:\n",
    "        # 1. Apacheadmissiondx: This can be quite vague so would need sufficient cleaning?\n",
    "        # 2. nursingChartOffset: Not sure what the relevance of this timestamp is?\n",
    "        # 3. Unitdischargeoffset: This doesn't make sense to use because it won't be available at the time of prediction, unless we were predicting based on the last values during the stay.\n",
    "        # 4. eyes / motor / verbal: These three values are already captured in the GCS, so there is no need to include it as additional variables.\n",
    "        # 5. invasive sys/dia/map: I swapped these out with noninvasive measures, as there are more samples (not everyone would be measured invasively) and should still approximate to the same values.\n",
    "        'age',\n",
    "        'ethnicity',\n",
    "        'gender',\n",
    "        'height',\n",
    "        'weight',\n",
    "        'sao2',\n",
    "        'systolic_noninvasive',\n",
    "        'diastolic_noninvasive',\n",
    "        'map_noninvasive',\n",
    "        'apache_heartrate',\n",
    "        'apache_respiratoryrate',\n",
    "        'apache_temperature',\n",
    "        'apache_glucose',\n",
    "        'apache_fio2',\n",
    "        'apache_ph',\n",
    "        'apache_gcs'\n",
    "    ],\n",
    "    'aki': [\n",
    "        # This was loosely based off this paper: https://www.nature.com/articles/s41598-021-97735-0\n",
    "        # - We did not include the following features, because there are some disagreements around how accurately these values are captured\n",
    "        # in the dataset, because not everyone may be on a catheter, and the window with which you calculate it, par around the idea of urine output. If performance is very\n",
    "        # low, we could always attempt to re-calculate it.\n",
    "        # 1. Hourly measures of urine output\n",
    "        # 2. Fluid intake\n",
    "        # 3. Fluid Balance (computed as fluid input minus output, normalized by weight)\n",
    "        'age',\n",
    "        'gender',\n",
    "        'weight',\n",
    "        'height',\n",
    "        'lean_body_mass',\n",
    "        'has_heartdisease',\n",
    "        'has_diabetes',\n",
    "        'has_cancer',\n",
    "        'vasopressin_used',\n",
    "        'diuretics_used',\n",
    "        'creatinine',\n",
    "        'map_noninvasive',\n",
    "    ],\n",
    "    # paper: https://pubmed.ncbi.nlm.nih.gov/36653875/\n",
    "    # new paper: https://www.nature.com/articles/s41598-024-63793-3\n",
    "    'aki_v2': [\n",
    "        'gender',\n",
    "        'age',\n",
    "        'sao2',\n",
    "        'apache_ph',\n",
    "        'apache_temperature',\n",
    "        'apache_heartrate',\n",
    "        'apache_respiratoryrate',\n",
    "        'apache_gcs',\n",
    "        'apache_fio2',\n",
    "        'apache_glucose',\n",
    "        'apache_bun',\n",
    "        'apache_creatinine',\n",
    "        'apache_wbc',\n",
    "        'apache_sodium',\n",
    "        'apache_hematocrit',\n",
    "        'apache_pco2',\n",
    "        'apache_pao2',\n",
    "        'bicarbonate',\n",
    "        'potassium',\n",
    "        'chloride',\n",
    "        'hemoglobin',\n",
    "        'platelet_count'\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Q1ZiRumMlTD",
    "outputId": "83ec4f7a-99e5-4e8b-90f9-4a619f7a8fe0"
   },
   "outputs": [],
   "source": [
    "df_features.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZocWXzsE84Q"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdzqmIj4cNGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Taken from PSET 1\n",
    "# Drop rows with any missing values\n",
    "\n",
    "# For numerical features (no need for an imputer now)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler())  # Scale numerical data\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For categorical features (no need for an imputer now)\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))  # One-hot encode categorical data\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting up the ColumnTransformer\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=[\"category\", object, \"string\"])),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=[\"category\", object, \"string\"]))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Complete preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessing\", preprocessing)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir6Opft6PfUM"
   },
   "outputs": [],
   "source": [
    "# For numerical features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),  # Impute missing values with mean\n",
    "        (\"scaler\", StandardScaler())  # Scale numerical data\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For categorical features\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing values with the most frequent value\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))  # One-hot encode categorical data\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"num\",\n",
    "            numeric_transformer,\n",
    "            selector(dtype_exclude=[\"category\", object, \"string\"]),\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            categorical_transformer,\n",
    "            selector(dtype_include=[\"category\", object, \"string\"]),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_pipeline_v2 = Pipeline(\n",
    "    steps=[(\"preprocessing\", preprocessing)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnKJ25j2bpys"
   },
   "outputs": [],
   "source": [
    "def preprocess(df, df_out, features, outcomes, impute=False):\n",
    "    # Drop rows with any NaNs in either DataFrame\n",
    "\n",
    "    if not impute:\n",
    "      df = df.dropna(subset=features).reset_index(drop=True)\n",
    "    df_out = df_out.dropna(subset=outcomes).reset_index(drop=True)\n",
    "\n",
    "    # Ensure 'uniquepid' is included in features\n",
    "    if 'uniquepid' not in features:\n",
    "        features.append('uniquepid')\n",
    "\n",
    "    # Select specified features from df\n",
    "    X = df[features]\n",
    "\n",
    "    # Filter df_out to include only those rows corresponding to X's 'uniquepid'\n",
    "    Y_df = df_out[df_out['uniquepid'].isin(X['uniquepid'])]\n",
    "\n",
    "    Y = pd.DataFrame()\n",
    "    for outcome in outcomes:\n",
    "        Y[outcome] = pd.to_numeric(Y_df[outcome], errors='coerce')\n",
    "\n",
    "    # Drop any rows where Y is NaN (failed conversion to numeric)\n",
    "    valid_indices = Y.dropna().index\n",
    "\n",
    "    # Get valid 'uniquepid's\n",
    "    valid_uniquepids = Y_df.loc[valid_indices, 'uniquepid']\n",
    "\n",
    "    # Align X to only include rows with valid 'uniquepid's\n",
    "    X_with_pid = X[X['uniquepid'].isin(valid_uniquepids)].reset_index(drop=True)\n",
    "    Y = Y.loc[valid_indices].reset_index(drop=True)\n",
    "    unique_pids = X_with_pid['uniquepid'].reset_index(drop=True)\n",
    "    X_with_pid = X_with_pid.drop(columns=['uniquepid'])\n",
    "\n",
    "    # Apply the preprocessing pipeline\n",
    "    if not impute:\n",
    "      X_processed = preprocessing_pipeline.fit_transform(X_with_pid)\n",
    "    else:\n",
    "      X_processed = preprocessing_pipeline_v2.fit_transform(X_with_pid)\n",
    "\n",
    "    return X_processed, Y, unique_pids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIQSHPbZFBPa"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4MRCRxIeGSE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(y_pred_proba, y_test, threshold=0.5):\n",
    "    # Convert probabilities to class labels based on threshold\n",
    "    y_pred_labels = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "    precision = precision_score(y_test, y_pred_labels, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_labels, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_labels, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLIdD-_5FQN2"
   },
   "source": [
    "#Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut4liUf5FVlY"
   },
   "source": [
    "##XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OZBIeSbFTE0"
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # For evaluation\n",
    "\n",
    "def train_and_evaluate_xgboost(X, Y, uniquepid, outcome):\n",
    "    print(\"Training XGBoost\")\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, pid_train, pid_test = train_test_split(\n",
    "        X, Y, uniquepid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Creating and fitting the XGBoost model\n",
    "    xgb_model = xgboost.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on the test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "\n",
    "    # Predicting class labels based on a threshold (default 0.5)\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(cm)\n",
    "\n",
    "    # evaluate_model(y_pred, y_test)\n",
    "\n",
    "    # Creating a DataFrame with true and predicted values along with uniquepid\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test.reset_index(drop=True),\n",
    "        f'actual_{outcome}': y_test.reset_index(drop=True),\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, xgb_model\n",
    "\n",
    "\n",
    "def train_and_evaluate_xgboost_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome):\n",
    "    print(\"Training XGBoost\")\n",
    "\n",
    "    # Creating and fitting the XGBoost model\n",
    "    xgb_model = xgboost.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on the test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "\n",
    "    # Predicting class labels based on a threshold (default 0.5)\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    print('xgboost', len(y_pred))\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(cm)\n",
    "\n",
    "    # evaluate_model(y_pred, y_test)\n",
    "\n",
    "    # Creating a DataFrame with true and predicted values along with uniquepid\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test,\n",
    "        f'actual_{outcome}': y_test,\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV-j9nd5HuZ8"
   },
   "source": [
    "##Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MHjGH4EHwRG"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_evaluate_logistic_regression(X, Y, uniquepid, outcome):\n",
    "    print(\"Training Logistic Regression\")\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test, pid_train, pid_test = train_test_split(\n",
    "        X, Y, uniquepid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Creating and fitting the model\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = lr_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "\n",
    "    # Predicting class labels based on a threshold\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Outcome DataFrame\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test.reset_index(drop=True),\n",
    "        f'actual_{outcome}': y_test.reset_index(drop=True),\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, lr_model\n",
    "\n",
    "\n",
    "def train_and_evaluate_logistic_regression_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome):\n",
    "    print(\"Training Logistic Regression\")\n",
    "    # Splitting the data\n",
    "    # X_train, X_test, y_train, y_test, pid_train, pid_test = train_test_split(\n",
    "    #     X, Y, uniquepid, test_size=0.2, random_state=42\n",
    "    # )\n",
    "\n",
    "    # Creating and fitting the model\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = lr_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "\n",
    "    # Predicting class labels based on a threshold\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    print('logreg', len(y_pred))\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Outcome DataFrame\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test,\n",
    "        f'actual_{outcome}': y_test,\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riuh--3DIVlB"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywIzyFCaIXRl"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_evaluate_random_forest(X, Y, uniquepid, outcome):\n",
    "    print(\"Training Random Forest\")\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test, pid_train, pid_test = train_test_split(\n",
    "        X, Y, uniquepid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Creating and fitting the model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Predicting class labels based on a threshold\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    print('rf', len(y_pred))\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Outcome DataFrame\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test.reset_index(drop=True),\n",
    "        f'actual_{outcome}': y_test.reset_index(drop=True),\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, rf_model\n",
    "\n",
    "def train_and_evaluate_random_forest_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome):\n",
    "    print(\"Training Random Forest\")\n",
    "\n",
    "    # Creating and fitting the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting probabilities on the test set\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "\n",
    "    # Predicting class labels based on a threshold (default 0.5)\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    print('random_forest', len(y_pred))\n",
    "\n",
    "    # Evaluation\n",
    "    evaluate_model(y_pred_proba, y_test)\n",
    "\n",
    "    # Creating a DataFrame with true and predicted values along with uniquepid\n",
    "    outcome_df = pd.DataFrame({\n",
    "        'uniquepid': pid_test.reset_index(drop=True),\n",
    "        f'actual_{outcome}': y_test.reset_index(drop=True),\n",
    "        f'predicted_{outcome}': y_pred\n",
    "    })\n",
    "\n",
    "    return outcome_df, rf_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ0YGbNeqwIA",
    "outputId": "508586a3-d480-4957-f160-6cacf6550e39"
   },
   "outputs": [],
   "source": [
    "all_features = list(set(features['length_of_stay'] + features['mortality'] + features['aki_v2']))\n",
    "outcomes = ['prolonged_length_of_stay', 'aki_status', 'hospital_mortality']\n",
    "feature_df = df_features\n",
    "X, Y, uniquepid, feature_list = preprocess(feature_df, df_outcomes, all_features, outcomes, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhwPuCXuWkw3",
    "outputId": "fe5b7dbf-a6a2-435c-84db-d5a8632084c6"
   },
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDyksJ0W1W38"
   },
   "source": [
    "# Run Analysis\n",
    "\n",
    "Uses selected features for each task only. Patients with nan values are dropped on a case by case basis based on the prediction tasks and the features necessary for that prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYGypZU51YfS"
   },
   "outputs": [],
   "source": [
    "def run_analysis(feature_list, outcome, feature_df):\n",
    "  X, Y, uniquepid = preprocess(feature_df, df_outcomes, feature_list, outcome)\n",
    "\n",
    "  print('-----------------------------------')\n",
    "  outcome1_df, xgb_model = train_and_evaluate_xgboost(X, Y, uniquepid, outcome)\n",
    "  print('-----------------------------------')\n",
    "  outcome2_df, lr_model = train_and_evaluate_logistic_regression(X, Y, uniquepid, outcome)\n",
    "  print('-----------------------------------')\n",
    "  outcome3_df, rf_model = train_and_evaluate_random_forest(X, Y, uniquepid, outcome)\n",
    "  print('-----------------------------------')\n",
    "\n",
    "\n",
    "  outcome1_df = outcome1_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_xgb'})\n",
    "  outcome2_df = outcome2_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_lr'})\n",
    "  outcome3_df = outcome3_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_rf'})\n",
    "\n",
    "  merged_df = outcome1_df.merge(\n",
    "      outcome2_df[['uniquepid', f'predicted_{outcome}_lr']],\n",
    "      on='uniquepid'\n",
    "  ).merge(\n",
    "      outcome3_df[['uniquepid', f'predicted_{outcome}_rf']],\n",
    "      on='uniquepid'\n",
    "  )\n",
    "\n",
    "  merged_df.to_csv(f'{outcome}_results.csv', index=False)\n",
    "\n",
    "\n",
    "def run_analysis_v2(feature_list, outcome, feature_df, df_outcomes, outcomes, impute):\n",
    "    # Preprocess the data\n",
    "    X, Y, uniquepid = preprocess(feature_df, df_outcomes, feature_list, outcomes, impute)\n",
    "\n",
    "    pd.DataFrame(X).to_csv('overall_train_test_features.csv')\n",
    "    pd.DataFrame(Y).to_csv('overall_train_test_outcomes.csv')\n",
    "\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, pid_train, pid_test = train_test_split(\n",
    "        X, Y[outcome], uniquepid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    # # Debugging: Check types and lengths\n",
    "    # print(\"Type of X_train:\", type(X_train))\n",
    "    # print(\"Type of pid_train:\", type(pid_train))\n",
    "    # print(\"Type of y_train:\", type(y_train))\n",
    "    # print(\"Length of X_train:\", len(X_train))\n",
    "    # print(\"Length of pid_train:\", len(pid_train))\n",
    "    # print(\"Length of y_train:\", len(y_train))\n",
    "\n",
    "    # # Ensure X_train and X_test are DataFrames\n",
    "    # if not isinstance(X_train, pd.DataFrame):\n",
    "    #     X_train = pd.DataFrame(X_train)\n",
    "    # if not isinstance(X_test, pd.DataFrame):\n",
    "    #     X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # # Ensure pid_train and pid_test are Series\n",
    "    # if not isinstance(pid_train, pd.Series):\n",
    "    #     pid_train = pd.Series(pid_train)\n",
    "    # if not isinstance(pid_test, pd.Series):\n",
    "    #     pid_test = pd.Series(pid_test)\n",
    "\n",
    "    # # Ensure y_train and y_test are DataFrames\n",
    "    # if isinstance(y_train, pd.Series):\n",
    "    #     y_train = y_train.to_frame(name=outcome)\n",
    "    # if isinstance(y_test, pd.Series):\n",
    "    #     y_test = y_test.to_frame(name=outcome)\n",
    "\n",
    "    # # Assign 'uniquepid' to X_train and X_test\n",
    "    # try:\n",
    "    #     X_train = X_train.reset_index(drop=True)\n",
    "    #     X_test = X_test.reset_index(drop=True)\n",
    "    #     pid_train = pid_train.reset_index(drop=True)\n",
    "    #     pid_test = pid_test.reset_index(drop=True)\n",
    "\n",
    "    #     X_train['uniquepid'] = pid_train\n",
    "    #     X_test['uniquepid'] = pid_test\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error during assigning 'uniquepid' to X_train/X_test: {e}\")\n",
    "    #     print(\"X_train columns before assignment:\", X_train.columns)\n",
    "    #     print(\"pid_train head:\", pid_train.head())\n",
    "    #     return\n",
    "\n",
    "    # # Assign 'uniquepid' to y_train and y_test\n",
    "    # try:\n",
    "    #     y_train['uniquepid'] = pid_train\n",
    "    #     y_test['uniquepid'] = pid_test\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error during assigning 'uniquepid' to y_train/y_test: {e}\")\n",
    "    #     print(\"y_train columns before assignment:\", y_train.columns)\n",
    "    #     print(\"pid_train head:\", pid_train.head())\n",
    "    #     return\n",
    "\n",
    "    # # Debugging: Verify assignments\n",
    "    # print(\"X_train columns after assignment:\", X_train.columns)\n",
    "    # print(\"y_train columns after assignment:\", y_train.columns)\n",
    "\n",
    "    # # Exporting DataFrames to CSV\n",
    "    # X_train.to_csv('training_set_features_df.csv', index=False)\n",
    "    # X_test.to_csv('test_set_features_df.csv', index=False)\n",
    "    # y_train.to_csv('training_set_outcomes_df.csv', index=False)\n",
    "    # y_test.to_csv('test_set_outcomes_df.csv', index=False)\n",
    "\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    # Train and evaluate models\n",
    "    outcome1_df, xgb_model = train_and_evaluate_xgboost_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome)\n",
    "    print('-----------------------------------')\n",
    "    outcome2_df, lr_model = train_and_evaluate_logistic_regression_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome)\n",
    "    print('-----------------------------------')\n",
    "    outcome3_df, rf_model = train_and_evaluate_random_forest_v2(X_train, X_test, y_train, y_test, pid_train, pid_test, outcome)\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    # Rename prediction columns\n",
    "    outcome1_df = outcome1_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_xgb'})\n",
    "    outcome2_df = outcome2_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_lr'})\n",
    "    outcome3_df = outcome3_df.rename(columns={f'predicted_{outcome}': f'predicted_{outcome}_rf'})\n",
    "\n",
    "    # Merge predictions on 'uniquepid'\n",
    "    merged_df = outcome1_df.merge(\n",
    "        outcome2_df[['uniquepid', f'predicted_{outcome}_lr']],\n",
    "        on='uniquepid'\n",
    "    ).merge(\n",
    "        outcome3_df[['uniquepid', f'predicted_{outcome}_rf']],\n",
    "        on='uniquepid'\n",
    "    )\n",
    "\n",
    "    # Export merged predictions to CSV\n",
    "    merged_df.to_csv(f'{outcome}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "RvcfHezc_NJY",
    "outputId": "7867b963-2f46-439a-d358-82be4b1eb564"
   },
   "outputs": [],
   "source": [
    "print('Prolonged Length of Stay')\n",
    "\n",
    "run_analysis(features['length_of_stay'], 'prolonged_length_of_stay', df_features)\n",
    "print('Mortality')\n",
    "run_analysis(features['mortality'], 'hospital_mortality', df_features)\n",
    "print('AKI')\n",
    "run_analysis(features['aki_v2'], 'aki_status', df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ3oKM1iS3Lo"
   },
   "source": [
    "# Standardize Training Set\n",
    "\n",
    "Basically concatenate features for all tasks, and run analysis on that dataframe. That way the same patients get dropped for having nan values, and we have a standardized training and test set across all tasks. This should make analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTDgkSUTDlli",
    "outputId": "bc954641-c9e9-417a-a5aa-feb0e0de4e91"
   },
   "outputs": [],
   "source": [
    "all_features = list(set(features['length_of_stay'] + features['mortality'] + features['aki_v2'] + ['uniquepid']))\n",
    "outcomes = list(['aki_status', 'prolonged_length_of_stay', 'hospital_mortality'])\n",
    "\n",
    "run_analysis_v2(all_features, 'hospital_mortality', df_features, df_outcomes, outcomes, impute=True)\n",
    "run_analysis_v2(all_features, 'aki_status', df_features, df_outcomes, outcomes, impute=True)\n",
    "run_analysis_v2(all_features, 'prolonged_length_of_stay', df_features, df_outcomes, outcomes, impute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ha8HXw1dTSlI",
    "outputId": "29b78bf2-9fdb-4886-ad14-efacf9ec4afa"
   },
   "outputs": [],
   "source": [
    "num_nans = pid_test.isna().sum()\n",
    "print(num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvedygQnTFjI"
   },
   "outputs": [],
   "source": [
    "pid_train.to_csv('trainpid.csv')\n",
    "pid_test.to_csv('testpid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXodLJEwaogA"
   },
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HN4AlW9eT7-l",
    "outputId": "15c4412c-6059-4a62-abba-248acd6bffaf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_demographics(uniquepids, df_features, categorical_columns=['ethnicity', 'gender'], numerical_columns=['age', 'weight']):\n",
    "    filtered_df = df_features[df_features['uniquepid'].isin(uniquepids)]\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "    for column in categorical_columns:\n",
    "        if column in filtered_df.columns:\n",
    "            value_counts = filtered_df[column].value_counts()\n",
    "            # Pie chart\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            colors = sns.color_palette(\"pastel\", len(value_counts))\n",
    "            plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "            plt.title(f\"Distribution of {column.capitalize()} (Pie Chart)\", fontsize=14, fontweight='bold')\n",
    "            plt.show()\n",
    "            # Bar chart\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x=value_counts.index, y=value_counts.values, palette=colors)\n",
    "            plt.title(f\"Distribution of {column.capitalize()} (Bar Chart)\", fontsize=14, fontweight='bold')\n",
    "            plt.ylabel(\"Count\", fontsize=12)\n",
    "            plt.xlabel(column.capitalize(), fontsize=12)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.show()\n",
    "    for column in numerical_columns:\n",
    "        if column in filtered_df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(filtered_df[column].dropna(), bins=20, kde=True, color=\"skyblue\")\n",
    "            plt.title(f\"Distribution of {column.capitalize()}\", fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(column.capitalize(), fontsize=12)\n",
    "            plt.ylabel(\"Frequency\", fontsize=12)\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "            plt.show()\n",
    "\n",
    "uniquepids = df_features['uniquepid'].unique()\n",
    "plot_demographics(\n",
    "    uniquepids=uniquepids,\n",
    "    df_features=df_features,\n",
    "    categorical_columns=['ethnicity', 'gender', 'has_diabetes', 'has_heartdisease', 'has_cancer', 'has_esrf'],\n",
    "    numerical_columns=['age', 'weight', 'height']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Hm4YKkVsczin",
    "outputId": "2d54591e-2e8a-4bcd-8c26-167efbd720c7"
   },
   "outputs": [],
   "source": [
    "df_features['uniquepid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvXudsZwGjmI",
    "outputId": "655eee24-1d22-40a8-ee8e-a601e0612b0f"
   },
   "outputs": [],
   "source": [
    "len(df_features['uniquepid'].unique()) == len(df_features['uniquepid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVqkIkp3IcOx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
